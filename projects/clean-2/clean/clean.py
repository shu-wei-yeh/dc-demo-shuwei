import h5py
import numpy as np
from pathlib import Path
import yaml
from typing import Optional

import torch
from lightning import pytorch as pl

from train.architectures import Architecture
from train.callbacks import PsdPlotter
from train.metrics import OnlinePsdRatio, PsdRatio

from train.data import DeepCleanDataset
from train.model import DeepClean
from utils.logging import configure_logging

# Placeholder imports for model and utility functions

from your_utility_module import load_model  # Assuming a utility function to load the model

def load_hdf5_data(file_path, dataset_name):
    """Load data from an HDF5 file."""
    with h5py.File(file_path, 'r') as f:
        data = f[dataset_name][:]
    return data

def predict_noise(model, strain, batch_size=64):
    """Predict noise from the strain data using the loaded model."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    model.eval()

    # Convert strain data to torch tensor and create DataLoader
    strain_tensor = torch.tensor(strain, dtype=torch.float32).to(device)
    data_loader = torch.utils.data.DataLoader(strain_tensor, batch_size=batch_size)

    predicted_noise = []
    with torch.no_grad():
        for batch in data_loader:
            noise = model(batch.unsqueeze(1)).squeeze()  # Assuming model requires input shape [batch, 1, length]
            predicted_noise.append(noise.cpu().numpy())

    return np.concatenate(predicted_noise)

def clean_strain(strain, predicted_noise):
    """Subtract predicted noise from strain to get the cleaned signal."""
    return strain - predicted_noise

def save_cleaned_data(cleaned_strain, file_path, dataset_name):
    """Save the cleaned strain data to an HDF5 file."""
    with h5py.File(file_path, 'w') as f:
        f.create_dataset(dataset_name, data=cleaned_strain)

def main():
    config_path = 'config_K1.yaml'
    output_hdf5_path = 'output.hdf5'  # Path to the output file generated by training
    model_checkpoint_path = 'last.ckpt'  # Path to the saved model checkpoint
    cleaned_data_path = 'cleaned_output.hdf5'  # Path to save the cleaned data
    cleaned_data_channel = 'K1:CAL-CS_PROC_DARM_STRAIN_DBL_DQ'

    # Load YAML configuration
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)

    # Initialize and load the model
    model_class_path = config['model']['arch']['class_path']
    model = DeepClean(**config['model']['arch']['init_args'])  # Update with actual model initialization
    model.load_state_dict(torch.load(model_checkpoint_path))

    # Load strain and noise data
    strain = load_hdf5_data(output_hdf5_path, 'strain')
    noise = load_hdf5_data(output_hdf5_path, 'noise')  # Assuming there's a noise dataset for reference or comparison

    # Predict noise and clean strain
    predicted_noise = predict_noise(model, strain)
    cleaned_strain = clean_strain(strain, predicted_noise)

    # Save cleaned data
    save_cleaned_data(cleaned_strain, cleaned_data_path, cleaned_data_channel)

if __name__ == '__main__':
    main()
