{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from lightning import pytorch as pl\n",
    "\n",
    "from train.architectures import Architecture\n",
    "from train.callbacks import ModelCheckpoint, PsdPlotter\n",
    "from train.metrics import OnlinePsdRatio, PsdRatio\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "\n",
    "class DeepClean(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        arch: Architecture,\n",
    "        loss: PsdRatio,\n",
    "        metric: OnlinePsdRatio,\n",
    "        patience: Optional[int] = None,\n",
    "        save_top_k_models: int = 10,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"arch\", \"loss\", \"metric\"])\n",
    "\n",
    "        self.model = arch\n",
    "        self.loss = loss\n",
    "        self.metric = metric\n",
    "        self.metric.loss_fn = self.loss\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        return self.model(X)\n",
    "\n",
    "    def training_step(self, batch: tuple[Tensor, Tensor]) -> Tensor:\n",
    "        X, y_true = batch\n",
    "        y_pred = self(X)\n",
    "        loss = self.loss(y_pred, y_true).mean()\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def _shared_eval_step(self, X, y_true) -> None:\n",
    "        \"\"\"\n",
    "        Note that the actual computation of the loss function\n",
    "        happens via the PsdPlotter Callback\n",
    "        \"\"\"\n",
    "\n",
    "        if y_true is not None:\n",
    "            self.metric.update(y_true[:, 0], \"strain\")\n",
    "        if X is not None:\n",
    "            y_pred = self(X)\n",
    "            self.metric.update(y_pred, \"predictions\")\n",
    "\n",
    "    def validation_step(self, batch, _) -> None:\n",
    "        return self._shared_eval_step(*batch)\n",
    "\n",
    "    def test_step(self, batch, _) -> None:\n",
    "        return self._shared_eval_step(*batch)\n",
    "\n",
    "    def configure_callbacks(self) -> list[pl.Callback]:\n",
    "        # first callback actually computes all of our\n",
    "        # validation metrics and any associated plots\n",
    "        callbacks = [PsdPlotter()]\n",
    "\n",
    "        # then tack on a checkpointer that uses these\n",
    "        # metrcis for checkpointing the model\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            save_top_k=self.hparams.save_top_k_models,\n",
    "            save_last=True,\n",
    "            auto_insert_metric_name=False,\n",
    "            mode=\"max\",\n",
    "        )\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "        # if we specified an early-stopping patience\n",
    "        # interval, add early stopping\n",
    "        if self.hparams.patience is not None:\n",
    "            early_stop = pl.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=self.hparams.patience,\n",
    "                mode=\"min\",\n",
    "                min_delta=0.00,\n",
    "            )\n",
    "            callbacks.append(early_stop)\n",
    "        return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume these are the initialization arguments for your components\n",
    "# You will need to adjust these based on your actual implementation\n",
    "architecture_args = {}  # Add your architecture arguments here\n",
    "psd_ratio_args = {}  # Add your PsdRatio arguments here\n",
    "online_psd_ratio_args = {}  # Add your OnlinePsdRatio arguments here\n",
    "\n",
    "# Instantiate your components with the appropriate arguments\n",
    "arch = Architecture(**architecture_args)\n",
    "loss = PsdRatio(**psd_ratio_args)\n",
    "metric = OnlinePsdRatio(**online_psd_ratio_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your checkpoint\n",
    "checkpoint_path = '/home/shuwei.yeh/deepclean/results/K1_train_test/lightning_logs/version_34/checkpoints/last.ckpt'\n",
    "\n",
    "# Load the model from the checkpoint, providing the required components\n",
    "model = DeepClean.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    arch=arch,\n",
    "    loss=loss,\n",
    "    metric=metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from train.architectures import Architecture  # Ensure this is correctly imported based on your project structure\n",
    "from train.metrics import OnlinePsdRatio, PsdRatio  # Same here\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "def load_model(checkpoint_path, arch, loss, metric):\n",
    "    \"\"\"\n",
    "    Load a DeepClean model from a checkpoint.\n",
    "    \n",
    "    Args:\n",
    "    - checkpoint_path (str): Path to the checkpoint file.\n",
    "    - arch (Architecture): The architecture of the model.\n",
    "    - loss (PsdRatio): The loss function used in the model.\n",
    "    - metric (OnlinePsdRatio): The metric used in the model.\n",
    "    \n",
    "    Returns:\n",
    "    - DeepClean: The loaded model.\n",
    "    \"\"\"\n",
    "    model = DeepClean.load_from_checkpoint(checkpoint_path=checkpoint_path, arch=arch, loss=loss, metric=metric)\n",
    "    return model\n",
    "\n",
    "def validate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Validate the model on a given DataLoader.\n",
    "    \n",
    "    Args:\n",
    "    - model (DeepClean): The model to validate.\n",
    "    - dataloader (DataLoader): DataLoader for validation data.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The validation loss.\n",
    "    \"\"\"\n",
    "    trainer = Trainer()\n",
    "    result = trainer.validate(model, dataloaders=dataloader)\n",
    "    return result\n",
    "\n",
    "# Specify the path to your checkpoint here\n",
    "checkpoint_path = '/home/shuwei.yeh/deepclean/results/K1_train_test/lightning_logs/version_34/checkpoints/last.ckpt'\n",
    "\n",
    "# You need to initialize `arch`, `loss`, and `metric` with proper arguments\n",
    "# This is placeholder code; you'll need to fill in with actual initializations\n",
    "arch = Architecture()  # Initialize your architecture here\n",
    "loss = PsdRatio()  # Initialize your loss function here\n",
    "metric = OnlinePsdRatio()  # Initialize your metric here\n",
    "\n",
    "# Load your model\n",
    "model = load_model(checkpoint_path, arch, loss, metric)\n",
    "\n",
    "# Assuming you have a DataLoader ready for validation\n",
    "# validation_dataloader = DataLoader(...)  # Initialize your DataLoader\n",
    "\n",
    "# Validate the model\n",
    "# Note: You need to uncomment the following line after setting up `validation_dataloader`\n",
    "# validation_loss = validate_model(model, validation_dataloader)\n",
    "# print(f\"Validation Loss: {validation_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected instantiation for PsdRatio\n",
    "sample_rate = 4096  # Example sample rate in Hz\n",
    "fftlength = 2  # Example FFT length in seconds\n",
    "freq_low = [55]  # Example lower frequency bounds\n",
    "freq_high = [65]  # Example upper frequency bounds\n",
    "loss = PsdRatio(sample_rate=sample_rate, fftlength=fftlength, freq_low=freq_low, freq_high=freq_high)\n",
    "\n",
    "# Assuming Architecture, bandpass filter, and y_scaler are correctly initialized\n",
    "arch = Architecture()  # Fill with actual initialization\n",
    "\n",
    "# Corrected instantiation for OnlinePsdRatio\n",
    "inference_sampling_rate = 64  # Same as sample rate for simplicity\n",
    "edge_pad = 0.25  # Example edge padding in seconds\n",
    "filter_pad = 0.25  # Example filter padding in seconds\n",
    "# Assuming `bandpass` is a callable for bandpass filtering and `y_scaler` is an instance of a scaling module\n",
    "bandpass_callable = lambda x: x  # Dummy bandpass callable, replace with actual\n",
    "y_scaler_module = torch.nn.Identity()  # Dummy scaler, replace with actual\n",
    "metric = OnlinePsdRatio(\n",
    "    inference_sampling_rate=inference_sampling_rate,\n",
    "    edge_pad=edge_pad,\n",
    "    filter_pad=filter_pad,\n",
    "    sample_rate=sample_rate,\n",
    "    bandpass=bandpass_callable,\n",
    "    y_scaler=y_scaler_module\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "from train.plotting import plot_psds\n",
    "from utils.plotting.utils import save\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from lightning import pytorch as pl\n",
    "\n",
    "from train.architectures import Architecture\n",
    "from train.callbacks import ModelCheckpoint, PsdPlotter\n",
    "from train.metrics import OnlinePsdRatio, PsdRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PsdPlotter(Callback):\n",
    "    def on_fit_start(self, trainer, pl_module):\n",
    "        log_dir = trainer.logger.log_dir or trainer.logger.save_dir\n",
    "\n",
    "        # TODO: support s3 here\n",
    "        self.plot_dir = os.path.join(log_dir, \"plots\")\n",
    "        os.makedirs(self.plot_dir, exist_ok=True)\n",
    "\n",
    "    def on_test_start(self, trainer, pl_module):\n",
    "        log_dir = trainer.logger.log_dir or trainer.logger.save_dir\n",
    "        self.test_dir = os.path.join(log_dir, \"test\")\n",
    "        os.makedirs(self.test_dir, exist_ok=True)\n",
    "\n",
    "    def log_plots(self, layout, fname, trainer):\n",
    "        # always save the plots locally\n",
    "        save(layout, fname, title=\"DeepClean PSDs\")\n",
    "\n",
    "        # if using W&B, log the plots as artifacts\n",
    "        if isinstance(trainer.logger, WandbLogger):\n",
    "            import wandb\n",
    "\n",
    "            key = os.path.basename(fname).split(\"-\")[0]\n",
    "            html = wandb.Html(fname)\n",
    "            trainer.logger.log_table(\n",
    "                \"samples\", columns=[f\"{key}-psds\"], data=[[html]]\n",
    "            )\n",
    "\n",
    "    def _shared_eval(self, pl_module):\n",
    "        # use our metric to produce the online-cleaned\n",
    "        # noise prediction and strain timeseries, calling\n",
    "        # compute to handle any distributed-training related\n",
    "        # aggregation, then compute our loss functions on\n",
    "        # these timeseries and log the output\n",
    "        noise, strain = pl_module.metric.compute(reduce=False)\n",
    "        pl_module.metric.reset()\n",
    "\n",
    "        spectral_density = pl_module.loss.spectral_density\n",
    "        fftlength = spectral_density.nperseg / pl_module.loss.sample_rate\n",
    "        p = plot_psds(\n",
    "            noise,\n",
    "            strain,\n",
    "            pl_module.loss.mask,\n",
    "            spectral_density,\n",
    "            fftlength,\n",
    "            pl_module.loss.asd,\n",
    "        )\n",
    "        return noise, strain, p\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # use our metric to produce the online-cleaned\n",
    "        # noise prediction and strain timeseries, calling\n",
    "        # compute to handle any distributed-training related\n",
    "        # aggregation, then compute our loss functions on\n",
    "        # these timeseries and log the output\n",
    "        noise, strain, p = self._shared_eval(pl_module)\n",
    "        loss = pl_module.loss(noise, strain)\n",
    "        pl_module.log(\n",
    "            \"val_loss\",\n",
    "            loss,\n",
    "            on_epoch=True,\n",
    "            sync_dist=True,\n",
    "            logger=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        # use these timeseries to plot their ASDs\n",
    "        # as well as their ratios\n",
    "        step = str(trainer.global_step).zfill(5)\n",
    "        fname = f\"val-psds_step-{step}.html\"\n",
    "        fname = os.path.join(self.plot_dir, fname)\n",
    "        self.log_plots(p, fname, trainer)\n",
    "\n",
    "    def on_test_epoch_end(self, trainer, pl_module):\n",
    "        noise, strain, p = self._shared_eval(pl_module)\n",
    "        loss = pl_module.loss(noise, strain)\n",
    "        pl_module.log(\n",
    "            \"test_loss\", loss, on_epoch=True, sync_dist=True, logger=True\n",
    "        )\n",
    "\n",
    "        fname = os.path.join(self.test_dir, \"test-psds.html\")\n",
    "        self.log_plots(p, fname, trainer)\n",
    "\n",
    "        fname = os.path.join(self.test_dir, \"outputs.hdf5\")\n",
    "        with h5py.File(fname, \"w\") as f:\n",
    "            f[\"noise\"] = noise.cpu().numpy()\n",
    "            f[\"strain\"] = strain.cpu().numpy()\n",
    "\n",
    "\n",
    "class ModelCheckpoint(ModelCheckpoint):\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        module = pl_module.__class__.load_from_checkpoint(\n",
    "            self.best_model_path,\n",
    "            arch=pl_module.model,\n",
    "            metric=pl_module.metric,\n",
    "            loss=pl_module.loss,\n",
    "        )\n",
    "\n",
    "        # TODO: we should probably establish an explicit\n",
    "        # validation_kernel_length that matches what\n",
    "        # we use at test time. If there were any issues\n",
    "        # with it, we would have caught it by now during\n",
    "        # validation, but worth making it explicit that\n",
    "        # these are different values.\n",
    "        datamodule = trainer.datamodule\n",
    "        kernel_size = int(\n",
    "            datamodule.hparams.kernel_length * datamodule.sample_rate\n",
    "        )\n",
    "\n",
    "        num_witnesses = len(datamodule.witness_channels)\n",
    "        sample_input = torch.randn(1, num_witnesses, kernel_size)\n",
    "        model = module.model.to(\"cpu\")\n",
    "        trace = torch.jit.trace(model, sample_input)\n",
    "\n",
    "        save_dir = trainer.logger.log_dir or trainer.logger.save_dir\n",
    "        if save_dir.startswith(\"s3://\"):\n",
    "            import s3fs\n",
    "\n",
    "            s3 = s3fs.S3FileSystem()\n",
    "            with s3.open(f\"{save_dir}/model.pt\", \"wb\") as f:\n",
    "                torch.jit.save(trace, f)\n",
    "        else:\n",
    "            with open(os.path.join(save_dir, \"model.pt\"), \"wb\") as f:\n",
    "                torch.jit.save(trace, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.Tensor\n",
    "\n",
    "\n",
    "class DeepClean(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        arch: Architecture,\n",
    "        loss: PsdRatio,\n",
    "        metric: OnlinePsdRatio,\n",
    "        patience: Optional[int] = None,\n",
    "        save_top_k_models: int = 10,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"arch\", \"loss\", \"metric\"])\n",
    "\n",
    "        self.model = arch\n",
    "        self.loss = loss\n",
    "        self.metric = metric\n",
    "        self.metric.loss_fn = self.loss\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        return self.model(X)\n",
    "\n",
    "    def training_step(self, batch: tuple[Tensor, Tensor]) -> Tensor:\n",
    "        X, y_true = batch\n",
    "        y_pred = self(X)\n",
    "        loss = self.loss(y_pred, y_true).mean()\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def _shared_eval_step(self, X, y_true) -> None:\n",
    "        \"\"\"\n",
    "        Note that the actual computation of the loss function\n",
    "        happens via the PsdPlotter Callback\n",
    "        \"\"\"\n",
    "\n",
    "        if y_true is not None:\n",
    "            self.metric.update(y_true[:, 0], \"strain\")\n",
    "        if X is not None:\n",
    "            y_pred = self(X)\n",
    "            self.metric.update(y_pred, \"predictions\")\n",
    "\n",
    "    def validation_step(self, batch, _) -> None:\n",
    "        return self._shared_eval_step(*batch)\n",
    "\n",
    "    def test_step(self, batch, _) -> None:\n",
    "        return self._shared_eval_step(*batch)\n",
    "\n",
    "    def configure_callbacks(self) -> list[pl.Callback]:\n",
    "        # first callback actually computes all of our\n",
    "        # validation metrics and any associated plots\n",
    "        callbacks = [PsdPlotter()]\n",
    "\n",
    "        # then tack on a checkpointer that uses these\n",
    "        # metrcis for checkpointing the model\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            save_top_k=self.hparams.save_top_k_models,\n",
    "            save_last=True,\n",
    "            auto_insert_metric_name=False,\n",
    "            mode=\"max\",\n",
    "        )\n",
    "        callbacks.append(checkpoint)\n",
    "\n",
    "        # if we specified an early-stopping patience\n",
    "        # interval, add early stopping\n",
    "        if self.hparams.patience is not None:\n",
    "            early_stop = pl.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=self.hparams.patience,\n",
    "                mode=\"min\",\n",
    "                min_delta=0.00,\n",
    "            )\n",
    "            callbacks.append(early_stop)\n",
    "        return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your checkpoint\n",
    "checkpoint_path = '/home/shuwei.yeh/deepclean/results/K1_train_test/lightning_logs/version_34/checkpoints/9-1270.ckpt'\n",
    "\n",
    "# Load the model from the checkpoint, providing the required components\n",
    "model = DeepClean.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    arch=arch,\n",
    "    loss=loss,\n",
    "    metric=metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger  # If you're using Weights & Biases for logging\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from train.model import DeepClean\n",
    "from train.data import DeepCleanDataset\n",
    "from train.callbacks import PsdPlotter, ModelCheckpoint\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed_everything(101588)\n",
    "\n",
    "def train_model():\n",
    "    # Initialize the data module\n",
    "    data_module = DeepCleanDataset(\n",
    "        fname='/home/shuwei.yeh/deepclean/data/K-K1_lldata-1369291863-12288.hdf5',\n",
    "        channels=['K1:CAL-CS_PROC_DARM_STRAIN_DBL_DQ', 'K1:PEM-MIC_OMC_BOOTH_OMC_Z_OUT_DQ'],  # Example channels\n",
    "        kernel_length=0.25,\n",
    "        freq_low=[55],  # Example frequency range\n",
    "        freq_high=[65],\n",
    "        batch_size=32,\n",
    "        train_duration=4096,  # 1 hour of training data\n",
    "        test_duration=8192,  # 10 minutes of test data\n",
    "        valid_frac=0.33,  # 10% of training data for validation\n",
    "        train_stride=0.0625,\n",
    "        inference_sampling_rate=64,\n",
    "        start_offset=0,\n",
    "        filt_order=8\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    model = DeepClean(\n",
    "        arch=Architecture(),  # Initialize your architecture here\n",
    "        loss=PsdRatio(sample_rate=4096, fftlength=4, freq_low=[55], freq_high=[65]),\n",
    "        metric=OnlinePsdRatio(\n",
    "            inference_sampling_rate=2048,\n",
    "            edge_pad=0.25,\n",
    "            filter_pad=0.5,\n",
    "            sample_rate=4096,\n",
    "            bandpass=lambda x: x,  # Dummy, replace with your bandpass function\n",
    "            y_scaler=torch.nn.Identity()  # Dummy, replace with your scaler\n",
    "        ),\n",
    "        patience=20,\n",
    "        save_top_k_models=3\n",
    "    )\n",
    "\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        PsdPlotter(),\n",
    "        ModelCheckpoint(monitor='val_loss', save_top_k=3, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, mode='min')\n",
    "    ]\n",
    "\n",
    "    # Optionally, define a logger\n",
    "    logger = WandbLogger(project='DeepCleanProject', log_model='all')\n",
    "\n",
    "    # Initialize the trainer\n",
    "    trainer = Trainer(\n",
    "        max_epochs=100,\n",
    "        #gpus=1,  # or -1 to use all available GPUs, or None to run on CPU\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        #progress_bar_refresh_rate=20  # Adjust as per your preference\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # Test the model\n",
    "    trainer.test(model, datamodule=data_module)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from train.model import DeepClean\n",
    "from train.data import DeepCleanDataset\n",
    "from train.callbacks import PsdPlotter\n",
    "from train.metrics import OnlinePsdRatio, PsdRatio\n",
    "from train.architectures import Architecture  # Ensure this is correctly defined and imported\n",
    "\n",
    "# Correcting the import for SpectralDensity and Metric if needed\n",
    "from ml4gw.transforms import SpectralDensity\n",
    "from torchmetrics import Metric\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed_everything(101588)\n",
    "\n",
    "\n",
    "class PsdRatio(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_rate: float,\n",
    "        fftlength: float,\n",
    "        freq_low: list[float],\n",
    "        freq_high: list[float],\n",
    "        overlap: Optional[float] = None,\n",
    "        asd: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.spectral_density = SpectralDensity(\n",
    "            sample_rate,\n",
    "            fftlength,\n",
    "            overlap=overlap,\n",
    "            average=\"median\",\n",
    "            fast=True,\n",
    "        )\n",
    "        self.asd = asd\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        N = int(fftlength * sample_rate / 2) + 1\n",
    "        mask = torch.zeros((N,), dtype=torch.bool)\n",
    "        for fl, fh in zip(freq_low, freq_high):\n",
    "            low = int(fl * fftlength)\n",
    "            high = int(fh * fftlength)\n",
    "            mask[low : high + 1] = 1\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "\n",
    "    def forward(self, pred, strain):\n",
    "        cleaned = strain - pred\n",
    "        residual = self.spectral_density(cleaned.double())\n",
    "        target = self.spectral_density(strain.double())\n",
    "\n",
    "        ratio = residual / target\n",
    "        ratio = ratio[:, self.mask]\n",
    "        if self.asd:\n",
    "            ratio = ratio**0.5\n",
    "        loss = ratio.mean(dim=-1)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class OnlinePsdRatio(Metric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inference_sampling_rate: float,\n",
    "        edge_pad: float,\n",
    "        filter_pad: float,\n",
    "        sample_rate: float,\n",
    "        bandpass: Callable,\n",
    "        y_scaler: torch.nn.Module,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.stride = int(sample_rate / inference_sampling_rate)\n",
    "        self.filter_pad = int(filter_pad * sample_rate)\n",
    "        self.edge_pad = int(edge_pad * sample_rate)\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        self.loss_fn = None\n",
    "        self.bandpass = bandpass\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "        self.add_state(\"predictions\", default=[])\n",
    "        self.add_state(\"strain\", default=[])\n",
    "\n",
    "    def update(self, y, kind):\n",
    "        if self.loss_fn is None:\n",
    "            raise ValueError(\"Must provide loss_fn before calling update\")\n",
    "        getattr(self, kind).append(y)\n",
    "\n",
    "    def clean(self):\n",
    "        # first build our overlapping predictions\n",
    "        # into a single timeseries of noise predictions\n",
    "        size = sum([i.numel() for i in self.strain])\n",
    "        batch_size = len(self.predictions[0])\n",
    "        device = self.predictions[0].device\n",
    "        dtype = self.predictions[0].dtype\n",
    "\n",
    "        y_pred = torch.zeros(\n",
    "            (size - self.edge_pad,), device=device, dtype=dtype\n",
    "        )\n",
    "\n",
    "        # for each predicted window, only slice out\n",
    "        # the single stride of new data from it that's\n",
    "        # sufficiently far from the edge to be considered\n",
    "        # \"safe\" and place it in the corresponding position\n",
    "        # in the full timeseries. We can do this array-style\n",
    "        # with some fancy indexing. We'll start by building\n",
    "        # the array of indices we'll grab from the predicted batches\n",
    "        get_idx = torch.arange(self.stride, device=device)\n",
    "        offset = int(self.sample_rate) - self.edge_pad - self.stride\n",
    "        get_idx += offset\n",
    "\n",
    "        # then turn this into a matrix of indices where\n",
    "        # each row of predictions will go in the timeseries\n",
    "        set_idx = get_idx.view(1, -1).repeat(batch_size, 1)\n",
    "        batch_offset = torch.arange(batch_size, device=device)\n",
    "        set_idx += batch_offset[:, None] * self.stride\n",
    "\n",
    "        for i, y in enumerate(self.predictions):\n",
    "            sidx = set_idx[: len(y)]\n",
    "            y_pred[sidx + i * batch_size * self.stride] = y[:, get_idx]\n",
    "\n",
    "            # for the very first frame, we have no choice\n",
    "            # but to fill the left side with our predictions.\n",
    "            # This won't really matter since we don't end up\n",
    "            # measuring ourselves on this frame, but we'll need\n",
    "            # it for providing filter padding.\n",
    "            if not i:\n",
    "                y_pred[:offset] = y[0, :offset]\n",
    "\n",
    "        # now clean the target timeseries in the\n",
    "        # online fashion, one frame at a time, plus\n",
    "        # some filter settle-in padding on each side.\n",
    "        # Ignore the first and last frames to account\n",
    "        # for this filter settle-in.\n",
    "        num_frames = int((len(y_pred) - self.filter_pad) // self.sample_rate)\n",
    "        noise = []\n",
    "        for i in range(1, num_frames - 1):\n",
    "            start = int(i * self.sample_rate) - self.filter_pad\n",
    "            stop = int((i + 1) * self.sample_rate) + self.filter_pad\n",
    "            noise.append(y_pred[start:stop])\n",
    "\n",
    "        # postprocess, doing the bandpass filtering back\n",
    "        # in numpy because torchaudio won't work\n",
    "        noise = torch.stack(noise)\n",
    "        noise = self.y_scaler(noise, reverse=True)\n",
    "        noise = self.bandpass(noise.cpu().numpy())\n",
    "        noise = torch.tensor(noise, device=device)\n",
    "\n",
    "        # slice out the filter padding so that the\n",
    "        # frames in each row are no longer overlapping,\n",
    "        # then reshape them to a proper timeseries\n",
    "        noise = noise[:, self.filter_pad : -self.filter_pad]\n",
    "        noise = noise.reshape(1, -1)\n",
    "\n",
    "        # reshape our raw strain into a timeseries\n",
    "        raw = torch.cat(self.strain, dim=0)[1 : num_frames - 1]\n",
    "        raw = raw.view(1, -1)\n",
    "        return noise, raw\n",
    "\n",
    "    def compute(self, reduce: bool = True):\n",
    "        noise, raw = self.clean()\n",
    "        if reduce:\n",
    "            return self.loss_fn(noise, raw).mean()\n",
    "        return noise, raw\n",
    "\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "seed_everything(101588)\n",
    "\n",
    "def train_model():\n",
    "    # Initialize the data module with corrected paths and parameters\n",
    "    data_module = DeepCleanDataset(\n",
    "        fname='/home/shuwei.yeh/deepclean/data/K-K1_lldata-1369291863-12288.hdf5',  # Correct path\n",
    "        channels=['K1:CAL-CS_PROC_DARM_STRAIN_DBL_DQ', 'K1:PEM-MIC_OMC_BOOTH_OMC_Z_OUT_DQ'],  # Correct channels\n",
    "        kernel_length=0.25,\n",
    "        freq_low=[55],\n",
    "        freq_high=[65],\n",
    "        batch_size=32,\n",
    "        train_duration=4096,  # Adjusted to seconds if needed\n",
    "        test_duration=8192,  # Adjusted to seconds if needed\n",
    "        valid_frac=0.33,\n",
    "        train_stride=0.0625,\n",
    "        inference_sampling_rate=64,\n",
    "        start_offset=0,\n",
    "        filt_order=8\n",
    "    )\n",
    "\n",
    "    # Initialize the model with corrected metrics and architecture\n",
    "    model = DeepClean(\n",
    "        arch=Architecture(),  # Correctly initialize your architecture here\n",
    "        loss=PsdRatio(sample_rate=4096, fftlength=4, freq_low=[55], freq_high=[65]),\n",
    "        metric=OnlinePsdRatio(\n",
    "            inference_sampling_rate=64,  # Corrected to match data_module's rate\n",
    "            edge_pad=0.25,\n",
    "            filter_pad=0.5,\n",
    "            sample_rate=4096,\n",
    "            bandpass=[55, 65],  # Replace with actual function\n",
    "            y_scaler=torch.nn.Module()  # Replace with actual scaler\n",
    "        ),\n",
    "        patience=20,\n",
    "        save_top_k_models=3\n",
    "    )\n",
    "\n",
    "    # Define callbacks with corrected ModelCheckpoint\n",
    "    callbacks = [\n",
    "        PsdPlotter(),\n",
    "        ModelCheckpoint(dirpath='/home/shuwei.yeh/deepclean/results/K1_train_test/lightning_logs/version_34/checkpoints/', filename='{epoch}-{val_loss:.2f}', monitor='val_loss', save_top_k=3, mode='min'),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, mode='min')\n",
    "    ]\n",
    "\n",
    "    # Optionally, define a logger\n",
    "    logger = WandbLogger(project='DeepCleanProject', log_model='all')\n",
    "\n",
    "    # Initialize the trainer with GPU configuration if available\n",
    "    trainer = Trainer(\n",
    "        max_epochs=100,\n",
    "        # gpus=1 if torch.cuda.is_available() else 0,  # Automatically use GPU if available\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        # progress_bar_refresh_rate=20  # Uncommented and adjusted\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "    # Test the model\n",
    "    trainer.test(datamodule=data_module)  # Updated to pass datamodule directly\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc-demo-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
