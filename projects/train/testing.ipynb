{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from train.data import DeepCleanDataset\n",
    "from train.model import DeepClean\n",
    "import torch\n",
    "\n",
    "from train.architectures import Architecture\n",
    "from train.metrics import OnlinePsdRatio, PsdRatio\n",
    "from collections.abc import Callable\n",
    "from typing import Optional\n",
    "\n",
    "from ml4gw.transforms import SpectralDensity\n",
    "from torchmetrics import Metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deepclean(config, data_dir=None, num_epochs=10, num_gpus=0):\n",
    "    model = DeepClean(\n",
    "        arch=Architecture(),\n",
    "        loss=PsdRatio(\n",
    "            sample_rate=config[\"sample_rate\"],\n",
    "            fftlength=config[\"fftlength\"],\n",
    "            freq_low=config[\"freq_low\"],\n",
    "            freq_high=config[\"freq_high\"],\n",
    "            asd=config[\"asd\"]\n",
    "        ),\n",
    "        metric=OnlinePsdRatio(\n",
    "            inference_sampling_rate=config[\"inference_sampling_rate\"],\n",
    "            edge_pad=config[\"edge_pad\"],\n",
    "            filter_pad=config[\"filter_pad\"],\n",
    "            sample_rate=config[\"sample_rate\"],\n",
    "            bandpass=Callable,  # Define or import your bandpass function\n",
    "            y_scaler=torch.nn.Module  # Define or import your scaler function\n",
    "        ),\n",
    "        patience=config[\"patience\"],\n",
    "        save_top_k_models=config[\"save_top_k_models\"]\n",
    "    )\n",
    "\n",
    "    data_module = DeepCleanDataset(\n",
    "        fname=os.path.join(data_dir, 'data/K-K1_lldata-1369291863-12288.hdf5'),\n",
    "        channels=['K1:CAL-CS_PROC_DARM_STRAIN_DBL_DQ', 'K1:PEM-MIC_OMC_BOOTH_OMC_Z_OUT_DQ'],\n",
    "        kernel_length=config[\"kernel_length\"],\n",
    "        freq_low=[config[\"freq_low\"]],\n",
    "        freq_high=[config[\"freq_high\"]],\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        train_duration=4096,\n",
    "        test_duration=8192,\n",
    "        valid_frac=0.33,\n",
    "        train_stride=0.0625,\n",
    "        inference_sampling_rate=64,\n",
    "        start_offset=0,\n",
    "        filt_order=8\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        logger=TensorBoardLogger(save_dir=tune.get_trial_dir(), name=\"\", version=\".\"),\n",
    "        max_epochs=num_epochs,\n",
    "        gpus=num_gpus,\n",
    "        callbacks=[\n",
    "            TuneReportCallback({\"loss\": \"val_loss\"}, on=\"validation_end\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "def tune_hyperparameters(num_samples=10, num_epochs=10, gpus_per_trial=0):\n",
    "    config = {\n",
    "        \"sample_rate\": tune.choice([2048, 4096]),\n",
    "        \"fftlength\": tune.choice([2, 4]),\n",
    "        \"freq_low\": tune.choice([55, 58]),\n",
    "        \"freq_high\": tune.choice([62, 65]),\n",
    "        # \"asd\": tune.choice([True, False]),\n",
    "        \"inference_sampling_rate\": tune.choice([64, 4]),\n",
    "        # \"edge_pad\": tune.uniform(0.1, 0.5),\n",
    "        # \"filter_pad\": tune.uniform(0.1, 0.5),\n",
    "        \"patience\": tune.choice([10, 20]),\n",
    "        \"save_top_k_models\": tune.choice([1, 3]),\n",
    "        \"batch_size\": tune.choice([32, 512]),\n",
    "        \"max_epochs\": tune.choice([20, 100])\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "\n",
    "    analysis = tune.run(\n",
    "        tune.with_parameters(\n",
    "            train_deepclean,\n",
    "            data_dir=\"/home/shuwei.yeh/deepclean/data\",\n",
    "            num_epochs=num_epochs,\n",
    "            num_gpus=gpus_per_trial),\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=tune.CLIReporter(parameter_columns=list(config.keys()))\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the number of samples and epochs for tuning\n",
    "    tune_hyperparameters(num_samples=10, num_epochs=10, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc-demo-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
